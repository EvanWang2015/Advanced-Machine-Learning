{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlgh2BcUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x619ff9dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50000)\n",
      "(784, 10000)\n",
      "(784, 10000)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1).T\n",
    "X_val_flatten = X_val.reshape(X_val.shape[0],-1).T\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1).T\n",
    "\n",
    "print(X_train_flatten.shape)\n",
    "print(X_val_flatten.shape)\n",
    "print(X_test_flatten.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50000)\n",
      "(10, 10000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Take one vector of labes and the total number of classes C, and return the one hot encoding.\n",
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Create a matrix where the i-th row corresponds to the ith class number and the jth column corresponds to the jth training example\n",
    "    So if example j had a lable i,  then entry (i,j) will be 1.\n",
    "\n",
    "    Arguments:\n",
    "    labels -- vector containing the lables\n",
    "    C -- number of classes, the depth of one hot dimension\n",
    "    \"\"\"\n",
    "    # Create a tf.constant equal to C(depth), name it 'C'\n",
    "    C = tf.constant(C, name=\"C\")\n",
    "    \n",
    "    # Use tr.one_hot, be careful with the axis\n",
    "    one_hot_matrix = tf.one_hot(labels, depth=C, axis = 0)\n",
    "    \n",
    "    # creat the session\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "\n",
    "# encode y with one-hot\n",
    "y_train_one_hot = one_hot_matrix(y_train, 10)\n",
    "y_val_one_hot = one_hot_matrix(y_val, 10)\n",
    "y_test_one_hot = one_hot_matrix(y_test, 10)\n",
    "\n",
    "print(y_train_one_hot.shape)\n",
    "print(y_val_one_hot.shape)\n",
    "print(y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create placeholders for X and Y\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\" \n",
    "    Create the placeholders for the tensorflow session\n",
    "    Arguments: \n",
    "    n_x -- Scalar, size of an image vector\n",
    "    n_y -- Scalar, number of classes \n",
    "    \n",
    "    Return:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and \"float\"\n",
    "    Y -- placeholder for the input lables, of shape [n_y, none] and \"float\"\n",
    "    \"\"\"\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [n_x, None], name= \"X\")\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None], name = \"Y\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize_Parameters in tensorflow\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are?\n",
    "    W1 : [50, 784]\n",
    "    b1 : [50, 1]\n",
    "    W2 : [10, 50]\n",
    "    b2 : [10, 1]\n",
    "    \n",
    "    returns: \n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2\n",
    "    \"\"\"\n",
    "    W1 =  tf.get_variable(\"W1\", [50,784], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 =  tf.get_variable(\"b1\", [50,1], initializer = tf.zeros_initializer())\n",
    "    W2 =  tf.get_variable(\"W2\", [10,50], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 =  tf.get_variable(\"b2\", [10,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2\n",
    "                 }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: Linear ->RELU ->Linear ->SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape(input size, number of examples)\n",
    "    parameter -- python dictionary containig parameters \"W1\", \"b1\", \"W2\", \"b2\"\n",
    "    \n",
    "    Returns:\n",
    "    Z2 -- the output of the last linear unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\"\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    \n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)\n",
    "    \n",
    "    return Z2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comput cost\n",
    "def compute_cost(Z2, Y):\n",
    "    \"\"\" \n",
    "    computes the cost\n",
    "    Arguments:\n",
    "    Z2 -- output of forward propagation(output of the last Linear unit), of shape(10, number of examples)\n",
    "    Y -- \"TRue\" label vector places holders, same shape as Z2\n",
    "    \n",
    "    Returns:\n",
    "    cost -- tensor of cost function\n",
    "    \"\"\"\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z2)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- input target, of shape (10, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation]\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches*mini_batch_size : ]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches*mini_batch_size : ]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 600, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y =  create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z2 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z2, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z2), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.858143\n",
      "Cost after epoch 100: 0.021122\n",
      "Cost after epoch 200: 0.002147\n",
      "Cost after epoch 300: 0.000093\n",
      "Cost after epoch 400: 0.000002\n",
      "Cost after epoch 500: 0.000000\n",
      "Cost after epoch 600: 0.000000\n",
      "Cost after epoch 700: 0.000000\n",
      "Cost after epoch 800: 0.000000\n",
      "Cost after epoch 900: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x61a2297b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9674\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train_flatten, y_train_one_hot, X_val_flatten, y_val_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
